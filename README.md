# Adversarial-Robustness-in-Neural-Networks-Implementation-and-Assessment-of-FGSM-BIM-and-PGD-Attacks
This repository implements and assesses adversarial attacks on neural networks, specifically focusing on Fast Gradient Sign Method (FGSM), Basic Iterative Method (BIM), and Projected Gradient Descent (PGD). Explore the code to understand the impact of these attacks on model performance and robustness.
